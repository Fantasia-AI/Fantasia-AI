import os
from dotenv import load_dotenv
import gradio as gr
from huggingface_hub import InferenceClient
import pandas as pd
from typing import List, Tuple
import json
from datetime import datetime

# í™˜ê²½ ë³€ìˆ˜ ì„¤ì •
HF_TOKEN = os.getenv("HF_TOKEN")

# LLM Models Definition
LLM_MODELS = {
    "Cohere c4ai-crp-08-2024": "CohereForAI/c4ai-command-r-plus-08-2024",  # Default
    "Meta Llama3.3-70B": "meta-llama/Llama-3.3-70B-Instruct"    # Backup model
}

class ChatHistory:
    def __init__(self):
        self.history = []
        self.history_file = "/tmp/chat_history.json"
        self.load_history()

    def add_conversation(self, user_msg: str, assistant_msg: str):
        conversation = {
            "timestamp": datetime.now().isoformat(),
            "messages": [
                {"role": "user", "content": user_msg},
                {"role": "assistant", "content": assistant_msg}
            ]
        }
        self.history.append(conversation)
        self.save_history()

    def format_for_display(self):
        # Gradio Chatbot ì»´í¬ë„ŒíŠ¸ì— ë§ëŠ” í˜•ì‹ìœ¼ë¡œ ë³€í™˜
        formatted = []
        for conv in self.history:
            formatted.append([
                conv["messages"][0]["content"],  # user message
                conv["messages"][1]["content"]   # assistant message
            ])
        return formatted

    def get_messages_for_api(self):
        # API í˜¸ì¶œì„ ìœ„í•œ ë©”ì‹œì§€ í˜•ì‹
        messages = []
        for conv in self.history:
            messages.extend([
                {"role": "user", "content": conv["messages"][0]["content"]},
                {"role": "assistant", "content": conv["messages"][1]["content"]}
            ])
        return messages

    def clear_history(self):
        self.history = []
        self.save_history()

    def save_history(self):
        try:
            with open(self.history_file, 'w', encoding='utf-8') as f:
                json.dump(self.history, f, ensure_ascii=False, indent=2)
        except Exception as e:
            print(f"íˆìŠ¤í† ë¦¬ ì €ì¥ ì‹¤íŒ¨: {e}")

    def load_history(self):
        try:
            if os.path.exists(self.history_file):
                with open(self.history_file, 'r', encoding='utf-8') as f:
                    self.history = json.load(f)
        except Exception as e:
            print(f"íˆìŠ¤í† ë¦¬ ë¡œë“œ ì‹¤íŒ¨: {e}")
            self.history = []


# ì „ì—­ ChatHistory ì¸ìŠ¤í„´ìŠ¤ ìƒì„±
chat_history = ChatHistory()

def get_client(model_name="Cohere c4ai-crp-08-2024"):
    try:
        return InferenceClient(LLM_MODELS[model_name], token=HF_TOKEN)
    except Exception:
        return InferenceClient(LLM_MODELS["Meta Llama3.3-70B"], token=HF_TOKEN)

def analyze_file_content(content, file_type):
    """Analyze file content and return structural summary"""
    if file_type in ['parquet', 'csv']:
        try:
            lines = content.split('\n')
            header = lines[0]
            columns = header.count('|') - 1
            rows = len(lines) - 3
            return f"ğŸ“Š ë°ì´í„°ì…‹ êµ¬ì¡°: {columns}ê°œ ì»¬ëŸ¼, {rows}ê°œ ë°ì´í„°"
        except:
            return "âŒ ë°ì´í„°ì…‹ êµ¬ì¡° ë¶„ì„ ì‹¤íŒ¨"
    
    lines = content.split('\n')
    total_lines = len(lines)
    non_empty_lines = len([line for line in lines if line.strip()])
    
    if any(keyword in content.lower() for keyword in ['def ', 'class ', 'import ', 'function']):
        functions = len([line for line in lines if 'def ' in line])
        classes = len([line for line in lines if 'class ' in line])
        imports = len([line for line in lines if 'import ' in line or 'from ' in line])
        return f"ğŸ’» ì½”ë“œ êµ¬ì¡°: {total_lines}ì¤„ (í•¨ìˆ˜: {functions}, í´ë˜ìŠ¤: {classes}, ì„í¬íŠ¸: {imports})"
    
    paragraphs = content.count('\n\n') + 1
    words = len(content.split())
    return f"ğŸ“ ë¬¸ì„œ êµ¬ì¡°: {total_lines}ì¤„, {paragraphs}ë‹¨ë½, ì•½ {words}ë‹¨ì–´"

def read_uploaded_file(file):
    if file is None:
        return "", ""
    try:
        file_ext = os.path.splitext(file.name)[1].lower()
        
        if file_ext == '.parquet':
            df = pd.read_parquet(file.name, engine='pyarrow')
            content = df.head(10).to_markdown(index=False)
            return content, "parquet"
        elif file_ext == '.csv':
            encodings = ['utf-8', 'cp949', 'euc-kr', 'latin1']
            for encoding in encodings:
                try:
                    df = pd.read_csv(file.name, encoding=encoding)
                    content = f"ğŸ“Š ë°ì´í„° ë¯¸ë¦¬ë³´ê¸°:\n{df.head(10).to_markdown(index=False)}\n\n"
                    content += f"\nğŸ“ˆ ë°ì´í„° ì •ë³´:\n"
                    content += f"- ì „ì²´ í–‰ ìˆ˜: {len(df)}\n"
                    content += f"- ì „ì²´ ì—´ ìˆ˜: {len(df.columns)}\n"
                    content += f"- ì»¬ëŸ¼ ëª©ë¡: {', '.join(df.columns)}\n"
                    content += f"\nğŸ“‹ ì»¬ëŸ¼ ë°ì´í„° íƒ€ì…:\n"
                    for col, dtype in df.dtypes.items():
                        content += f"- {col}: {dtype}\n"
                    null_counts = df.isnull().sum()
                    if null_counts.any():
                        content += f"\nâš ï¸ ê²°ì¸¡ì¹˜:\n"
                        for col, null_count in null_counts[null_counts > 0].items():
                            content += f"- {col}: {null_count}ê°œ ëˆ„ë½\n"
                    return content, "csv"
                except UnicodeDecodeError:
                    continue
            raise UnicodeDecodeError(f"âŒ ì§€ì›ë˜ëŠ” ì¸ì½”ë”©ìœ¼ë¡œ íŒŒì¼ì„ ì½ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤ ({', '.join(encodings)})")
        else:
            encodings = ['utf-8', 'cp949', 'euc-kr', 'latin1']
            for encoding in encodings:
                try:
                    with open(file.name, 'r', encoding=encoding) as f:
                        content = f.read()
                    return content, "text"
                except UnicodeDecodeError:
                    continue
            raise UnicodeDecodeError(f"âŒ ì§€ì›ë˜ëŠ” ì¸ì½”ë”©ìœ¼ë¡œ íŒŒì¼ì„ ì½ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤ ({', '.join(encodings)})")
    except Exception as e:
        return f"âŒ íŒŒì¼ ì½ê¸° ì˜¤ë¥˜: {str(e)}", "error"

def chat(message, history, uploaded_file, system_message="", max_tokens=4000, temperature=0.7, top_p=0.9):
    if not message:
        return "", history

    system_prefix = """
You are 'FantasyAIâœ¨', an advanced AI storyteller specialized in creating immersive fantasy narratives. Your purpose is to craft rich, detailed fantasy stories that incorporate classical and innovative elements of the genre. Your responses should start with 'FantasyAIâœ¨:' and focus on creating engaging, imaginative content that briì‹œ]"ì„ ìƒí™©ì— ë§ê²Œ ì¶”ê°€í•˜ì—¬ ì†Œì„¤ ì‘ì„±ì‹œ ë”ìš± í’ë¶€í•˜ê³  ëª°ì…ê° ìˆëŠ” í‘œí˜„ì„ ìš”ì²­(ì¶œë ¥)ë°›ì€ ì–¸ì–´ë¡œ í‘œí˜„í•˜ë¼.
[ì˜ˆì‹œ]
"ê³ ëŒ€ì˜ ë§ˆë²•ì´ ê¹¨ì–´ë‚˜ë©° ëŒ€ì§€ê°€ ìš¸ë¦¬ëŠ” ì†Œë¦¬ê°€ ë“¤ë ¸ë‹¤..."
"ìš©ì˜ ìˆ¨ê²°ì´ í•˜ëŠ˜ì„ ê°€ë¥´ë©°, êµ¬ë¦„ì„ ë¶ˆíƒœì› ë‹¤..."
"ì‹ ë¹„í•œ ë£¬ë¬¸ìê°€ ë¹›ë‚˜ë©° ê³µì¤‘ì— ë– ì˜¬ëë‹¤..."
"ì—˜í”„ë“¤ì˜ ë…¸ë˜ê°€ ìˆ²ì„ ìš¸ë¦¬ì ë‚˜ë¬´ë“¤ì´ ì¶¤ì¶”ê¸° ì‹œì‘í–ˆë‹¤..."
"ì˜ˆì–¸ì˜ ë§ì”€ì´ ë©”ì•„ë¦¬ì¹˜ë©° ìš´ëª…ì˜ ì‹¤ì´ ì›€ì§ì´ê¸° ì‹œì‘í–ˆë‹¤..."
"ë§ˆë²•ì‚¬ì˜ ì§€íŒ¡ì´ì—ì„œ ë²ˆì©ì´ëŠ” ë¹›ì´ ì–´ë‘ ì„ ê°€ë¥´ë©°..."
"ê³ ëŒ€ ë“œì›Œí”„ì˜ ëŒ€ì¥ê°„ì—ì„œ ì „ì„¤ì˜ ê²€ì´ ë§Œë“¤ì–´ì§€ê³  ìˆì—ˆë‹¤..."
"ìˆ˜ì •êµ¬ìŠ¬ ì†ì— ë¹„ì¹œ ë¯¸ë˜ì˜ í™˜ì˜ì´ ì„œì„œíˆ ëª¨ìŠµì„ ë“œëŸ¬ëƒˆë‹¤..."
"ì‹ ì„±í•œ ê²°ê³„ê°€ ê¹¨ì–´ì§€ë©° ë´‰ì¸ëœ ì•…ì´ ê¹¨ì–´ë‚¬ë‹¤..."
"ì˜ì›…ì˜ ë°œê±¸ìŒì´ ìš´ëª…ì˜ ê¸¸ì„ ë”°ë¼ ìš¸ë ¤ í¼ì¡Œë‹¤..."

"""

    try:
        # íŒŒì¼ ì—…ë¡œë“œ ì²˜ë¦¬
        if uploaded_file:
            content, file_type = read_uploaded_file(uploaded_file)
            if file_type == "error":
                error_message = content
                chat_history.add_conversation(message, error_message)
                return "", history + [[message, error_message]]
            
            file_summary = analyze_file_content(content, file_type)
            
            if file_type in ['parquet', 'csv']:
                system_message += f"\n\níŒŒì¼ ë‚´ìš©:\n```markdown\n{content}\n```"
            else:
                system_message += f"\n\níŒŒì¼ ë‚´ìš©:\n```\n{content}\n```"
                
            if message == "íŒŒì¼ ë¶„ì„ì„ ì‹œì‘í•©ë‹ˆë‹¤...":
                message = f"""[íŒŒì¼ êµ¬ì¡° ë¶„ì„] {file_summary}
ë‹¤ìŒ ê´€ì ì—ì„œ ë„ì›€ì„ ë“œë¦¬ê² ìŠµë‹ˆë‹¤:
1. ğŸ“‹ ì „ë°˜ì ì¸ ë‚´ìš© íŒŒì•…
2. ğŸ’¡ ì£¼ìš” íŠ¹ì§• ì„¤ëª…
3. ğŸ¯ ì‹¤ìš©ì ì¸ í™œìš© ë°©ì•ˆ
4. âœ¨ ê°œì„  ì œì•ˆ
5. ğŸ’¬ ì¶”ê°€ ì§ˆë¬¸ì´ë‚˜ í•„ìš”í•œ ì„¤ëª…"""

        # ë©”ì‹œì§€ ì²˜ë¦¬
        messages = [{"role": "system", "content": system_prefix + system_message}]
        
        # ì´ì „ ëŒ€í™” íˆìŠ¤í† ë¦¬ ì¶”ê°€
        if history:
            for user_msg, assistant_msg in history:
                messages.append({"role": "user", "content": user_msg})
                messages.append({"role": "assistant", "content": assistant_msg})
        
        messages.append({"role": "user", "content": message})

        # API í˜¸ì¶œ ë° ì‘ë‹µ ì²˜ë¦¬
        client = get_client()
        partial_message = ""
        
        for msg in client.chat_completion(
            messages,
            max_tokens=max_tokens,
            stream=True,
            temperature=temperature,
            top_p=top_p,
        ):
            token = msg.choices[0].delta.get('content', None)
            if token:
                partial_message += token
                current_history = history + [[message, partial_message]]
                yield "", current_history

        # ì™„ì„±ëœ ëŒ€í™” ì €ì¥
        chat_history.add_conversation(message, partial_message)
        
    except Exception as e:
        error_msg = f"âŒ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"
        chat_history.add_conversation(message, error_msg)
        yield "", history + [[message, error_msg]]

with gr.Blocks(theme="Yntec/HaleyCH_Theme_Orange", title="GiniGEN ğŸ¤–") as demo:
    # ê¸°ì¡´ íˆìŠ¤í† ë¦¬ ë¡œë“œ
    initial_history = chat_history.format_for_display()
    with gr.Row():
        with gr.Column(scale=2):
            chatbot = gr.Chatbot(
                value=initial_history,  # ì €ì¥ëœ íˆìŠ¤í† ë¦¬ë¡œ ì´ˆê¸°í™”
                height=600, 
                label="ëŒ€í™”ì°½ ğŸ’¬",
                show_label=True
            )    


            msg = gr.Textbox(
                label="ë©”ì‹œì§€ ì…ë ¥",
                show_label=False,
                placeholder="ë¬´ì—‡ì´ë“  ë¬¼ì–´ë³´ì„¸ìš”... ğŸ’­",
                container=False
            )
            with gr.Row():
                clear = gr.ClearButton([msg, chatbot], value="ëŒ€í™”ë‚´ìš© ì§€ìš°ê¸°")
                send = gr.Button("ë³´ë‚´ê¸° ğŸ“¤")
        
        with gr.Column(scale=1):
            gr.Markdown("### GiniGEN ğŸ¤– [íŒŒì¼ ì—…ë¡œë“œ] ğŸ“\nì§€ì› í˜•ì‹: í…ìŠ¤íŠ¸, ì½”ë“œ, CSV, Parquet íŒŒì¼")
            file_upload = gr.File(
                label="íŒŒì¼ ì„ íƒ",
                file_types=["text", ".csv", ".parquet"],
                type="filepath"
            )
            
            with gr.Accordion("ê³ ê¸‰ ì„¤ì • âš™ï¸", open=False):
                system_message = gr.Textbox(label="ì‹œìŠ¤í…œ ë©”ì‹œì§€ ğŸ“", value="")
                max_tokens = gr.Slider(minimum=1, maximum=8000, value=4000, label="ìµœëŒ€ í† í° ìˆ˜ ğŸ“Š")
                temperature = gr.Slider(minimum=0, maximum=1, value=0.7, label="ì°½ì˜ì„± ìˆ˜ì¤€ ğŸŒ¡ï¸")
                top_p = gr.Slider(minimum=0, maximum=1, value=0.9, label="ì‘ë‹µ ë‹¤ì–‘ì„± ğŸ“ˆ")

    # ì˜ˆì‹œ ì§ˆë¬¸
    gr.Examples(
        examples=[
            ["í¥ë¯¸ë¡œìš´ ì†Œì¬ 10ê°€ì§€ë¥¼ ì œì‹œí•´ì¤˜ìš” ğŸ¤"],
            ["ë”ìš± ìê·¹ì ì´ê³  ë¬˜ì‚¬ë¥¼ ìì„¸íˆí•´ì¤˜ìš” ğŸ“š"],
            ["ì¡°ì„ ì‹œëŒ€ ë°°ê²½ìœ¼ë¡œ í•´ì¤˜ìš” ğŸ¯"],
            ["ê¸ˆê¸°ëœ ìš•ë§ì„ ì•Œë ¤ì¤˜ìš” âœ¨"],
            ["ê³„ì† ì´ì–´ì„œ ì‘ì„±í•´ì¤˜ ğŸ¤”"],
        ],
        inputs=msg,
    )

    # ëŒ€í™”ë‚´ìš© ì§€ìš°ê¸° ë²„íŠ¼ì— íˆìŠ¤í† ë¦¬ ì´ˆê¸°í™” ê¸°ëŠ¥ ì¶”ê°€
    def clear_chat():
        chat_history.clear_history()
        return None, None

    # ì´ë²¤íŠ¸ ë°”ì¸ë”©
    msg.submit(
        chat,
        inputs=[msg, chatbot, file_upload, system_message, max_tokens, temperature, top_p],
        outputs=[msg, chatbot]
    )

    send.click(
        chat,
        inputs=[msg, chatbot, file_upload, system_message, max_tokens, temperature, top_p],
        outputs=[msg, chatbot]
    )

    clear.click(
        clear_chat,
        outputs=[msg, chatbot]
    )

    # íŒŒì¼ ì—…ë¡œë“œì‹œ ìë™ ë¶„ì„
    file_upload.change(
        lambda: "íŒŒì¼ ë¶„ì„ì„ ì‹œì‘í•©ë‹ˆë‹¤...",
        outputs=msg
    ).then(
        chat,
        inputs=[msg, chatbot, file_upload, system_message, max_tokens, temperature, top_p],
        outputs=[msg, chatbot]
    )

if __name__ == "__main__":
    demo.launch()        